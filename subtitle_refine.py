import os
import sys
import subprocess
import argparse
from pathlib import Path
from google import genai
from google.genai import types
from typing import Optional
import asyncio
import time
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# è¨­å®š FFmpeg è·¯å¾‘ï¼ˆä½¿ç”¨ static-ffmpegï¼‰
FFMPEG_CMD = "ffmpeg"  # é è¨­å€¼
FFMPEG_AVAILABLE = False

def get_ffmpeg_path():
    """å–å¾— FFmpeg è·¯å¾‘"""
    global FFMPEG_CMD, FFMPEG_AVAILABLE

    try:
        from static_ffmpeg import run
        # å–å¾— static-ffmpeg æä¾›çš„ ffmpeg è·¯å¾‘
        ffmpeg_path, ffprobe_path = run.get_or_fetch_platform_executables_else_raise()
        FFMPEG_CMD = ffmpeg_path
        FFMPEG_AVAILABLE = True
        return ffmpeg_path
    except ImportError:
        # å¦‚æœæ²’æœ‰å®‰è£ static-ffmpegï¼Œå˜—è©¦ä½¿ç”¨ç³»çµ±çš„ ffmpeg
        pass
    except Exception as e:
        # å…¶ä»–éŒ¯èª¤ï¼Œè¨˜éŒ„ä½†ä¸ä¸­æ–·
        print(f"âš ï¸  static-ffmpeg åˆå§‹åŒ–è­¦å‘Š: {e}")

    # å˜—è©¦ä½¿ç”¨ç³»çµ±çš„ ffmpeg
    try:
        import shutil
        system_ffmpeg = shutil.which("ffmpeg")
        if system_ffmpeg:
            FFMPEG_CMD = system_ffmpeg
            FFMPEG_AVAILABLE = True
            return system_ffmpeg
    except:
        pass

    return "ffmpeg"  # é™ç´šåˆ°é è¨­å€¼

class VideoSubtitleProcessor:
    def __init__(
        self, 
        gemini_api_key: Optional[str] = None, 
        whisper_model: str = "base", 
        source_language: str = "zh",
        gemini_model: str = "gemini-2.5-flash"
    ):
        """
        åˆå§‹åŒ–å½±ç‰‡å­—å¹•è™•ç†å™¨
        
        Args:
            gemini_api_key: Gemini API é‡‘é‘°ï¼ˆonly-embed æ¨¡å¼å¯ä»¥ä¸æä¾›ï¼‰
            whisper_model: Whisper æ¨¡å‹å¤§å° (tiny, base, small, medium, large)
            source_language: å½±ç‰‡èªè¨€ä»£ç¢¼ (zh, en, ja, ko, es, fr ç­‰ï¼Œæˆ– auto è‡ªå‹•åµæ¸¬)
            gemini_model: Gemini æ¨¡å‹åç¨±
        """
        self.whisper_model = whisper_model
        self.source_language = source_language
        self.gemini_model = gemini_model
        
        # åªåœ¨æœ‰ API key æ™‚æ‰åˆå§‹åŒ– Gemini client
        if gemini_api_key:
            os.environ['GEMINI_API_KEY'] = gemini_api_key
            self.client = genai.Client(api_key=gemini_api_key)
        else:
            self.client = None
        
    def download_youtube_video(self, url: str, output_dir: str = "./downloads") -> str:
        """
        ä½¿ç”¨ yt-dlp ä¸‹è¼‰ YouTube å½±ç‰‡
        
        Args:
            url: YouTube å½±ç‰‡ç¶²å€
            output_dir: è¼¸å‡ºç›®éŒ„
            
        Returns:
            ä¸‹è¼‰çš„å½±ç‰‡æª”æ¡ˆè·¯å¾‘
        """
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ YouTube å½±ç‰‡: {url}")
        
        os.makedirs(output_dir, exist_ok=True)
        output_template = os.path.join(output_dir, "%(title)s.%(ext)s")
        
        cmd = [
            "yt-dlp",
            "-f", "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
            "-o", output_template,
            url
        ]
        
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            # å¾è¼¸å‡ºä¸­æ‰¾åˆ°ä¸‹è¼‰çš„æª”æ¡ˆåç¨±
            for line in result.stdout.split('\n'):
                if 'Merging formats into' in line or 'has already been downloaded' in line:
                    video_path = line.split('"')[1]
                    print(f"âœ… å½±ç‰‡ä¸‹è¼‰å®Œæˆ: {video_path}")
                    return video_path
                    
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå˜—è©¦åœ¨ç›®éŒ„ä¸­æ‰¾æœ€æ–°çš„æª”æ¡ˆ
            video_files = list(Path(output_dir).glob("*.mp4"))
            if video_files:
                latest_file = max(video_files, key=lambda p: p.stat().st_mtime)
                print(f"âœ… å½±ç‰‡ä¸‹è¼‰å®Œæˆ: {latest_file}")
                return str(latest_file)
                
        except subprocess.CalledProcessError as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e.stderr}")
            raise
            
        raise Exception("ç„¡æ³•æ‰¾åˆ°ä¸‹è¼‰çš„å½±ç‰‡æª”æ¡ˆ")
    
    def transcribe_video(self, video_path: str, output_dir: str = "./subtitles") -> str:
        """
        ä½¿ç”¨ Whisper è½‰éŒ„å½±ç‰‡å­—å¹•
        
        Args:
            video_path: å½±ç‰‡æª”æ¡ˆè·¯å¾‘
            output_dir: å­—å¹•è¼¸å‡ºç›®éŒ„
            
        Returns:
            å­—å¹•æª”æ¡ˆè·¯å¾‘ (.srt)
        """
        lang_display = "è‡ªå‹•åµæ¸¬" if self.source_language == "auto" else self.source_language
        print(f"ğŸ¤ æ­£åœ¨ä½¿ç”¨ Whisper è½‰éŒ„å­—å¹• (æ¨¡å‹: {self.whisper_model}, èªè¨€: {lang_display})...")
        
        os.makedirs(output_dir, exist_ok=True)
        video_name = Path(video_path).stem
        subtitle_path = os.path.join(output_dir, f"{video_name}.srt")
        
        cmd = [
            "whisper",
            video_path,
            "--model", self.whisper_model,
            "--output_format", "srt",
            "--output_dir", output_dir
        ]
        
        # å¦‚æœä¸æ˜¯è‡ªå‹•åµæ¸¬ï¼Œå‰‡æŒ‡å®šèªè¨€
        if self.source_language != "auto":
            cmd.extend(["--language", self.source_language])
        
        try:
            subprocess.run(cmd, check=True)
            print(f"âœ… å­—å¹•è½‰éŒ„å®Œæˆ: {subtitle_path}")
            return subtitle_path
        except subprocess.CalledProcessError as e:
            print(f"âŒ è½‰éŒ„å¤±æ•—: {e}")
            raise
    
    def read_subtitle_file(self, subtitle_path: str) -> str:
        """è®€å–å­—å¹•æª”æ¡ˆå…§å®¹"""
        with open(subtitle_path, 'r', encoding='utf-8') as f:
            return f.read()

    def _split_subtitle_into_chunks(self, subtitle_content: str, max_chars: int = 15000) -> list:
        """
        å°‡å­—å¹•åˆ†å‰²æˆå¤šå€‹ç‰‡æ®µï¼ˆåŸºæ–¼å­—å…ƒæ•¸é‡è€Œéæ¢ç›®æ•¸ï¼‰

        Args:
            subtitle_content: å®Œæ•´çš„å­—å¹•å…§å®¹
            max_chars: æ¯å€‹ç‰‡æ®µæœ€å¤šåŒ…å«çš„å­—å…ƒæ•¸ï¼ˆé è¨­ 15000ï¼‰

        Returns:
            å­—å¹•ç‰‡æ®µåˆ—è¡¨
        """
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åˆ†å‰²å­—å¹•æ¢ç›®ï¼ˆæ¯å€‹æ¢ç›®åŒ…å«ï¼šåºè™Ÿã€æ™‚é–“è»¸ã€æ–‡å­—ã€ç©ºè¡Œï¼‰
        # SRT æ ¼å¼ï¼šåºè™Ÿ\næ™‚é–“è»¸\næ–‡å­—\nç©ºè¡Œ
        entries = re.split(r'\n\n+', subtitle_content.strip())

        chunks = []
        current_chunk = []
        current_chars = 0

        for entry in entries:
            entry_length = len(entry)

            # å¦‚æœåŠ å…¥é€™å€‹æ¢ç›®æœƒè¶…éé™åˆ¶ï¼Œä¸”ç•¶å‰ chunk ä¸ç‚ºç©ºï¼Œå‰‡é–‹å§‹æ–°çš„ chunk
            if current_chars + entry_length > max_chars and current_chunk:
                chunks.append('\n\n'.join(current_chunk))
                current_chunk = []
                current_chars = 0

            # åŠ å…¥ç•¶å‰æ¢ç›®
            current_chunk.append(entry)
            current_chars += entry_length + 2  # +2 for '\n\n'

        # åŠ å…¥æœ€å¾Œä¸€å€‹ chunk
        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))

        return chunks

    def _merge_subtitle_chunks(self, chunks: list) -> str:
        """
        åˆä½µå­—å¹•ç‰‡æ®µä¸¦é‡æ–°ç·¨è™Ÿ

        Args:
            chunks: å­—å¹•ç‰‡æ®µåˆ—è¡¨

        Returns:
            åˆä½µå¾Œçš„å®Œæ•´å­—å¹•
        """
        all_entries = []
        for chunk in chunks:
            # åˆ†å‰²æ¯å€‹ç‰‡æ®µä¸­çš„æ¢ç›®
            entries = re.split(r'\n\n+', chunk.strip())
            all_entries.extend(entries)

        # é‡æ–°ç·¨è™Ÿ
        renumbered_entries = []
        counter = 1
        for entry in all_entries:
            lines = entry.strip().split('\n')
            if len(lines) >= 2:  # è‡³å°‘è¦æœ‰åºè™Ÿå’Œæ™‚é–“è»¸
                # æ›¿æ›ç¬¬ä¸€è¡Œçš„åºè™Ÿ
                lines[0] = str(counter)
                renumbered_entries.append('\n'.join(lines))
                counter += 1

        return '\n\n'.join(renumbered_entries)

    def _fix_srt_timestamp(self, timestamp: str) -> str:
        """
        ä¿®æ­£ SRT æ™‚é–“æˆ³æ ¼å¼

        Args:
            timestamp: æ™‚é–“æˆ³å­—ä¸²ï¼ˆä¾‹å¦‚ï¼š"0007:43,000" æˆ– "00:07:43,000"ï¼‰

        Returns:
            ä¿®æ­£å¾Œçš„æ™‚é–“æˆ³ï¼ˆä¾‹å¦‚ï¼š"00:07:43,000"ï¼‰
        """
        # ç§»é™¤æ‰€æœ‰ç©ºæ ¼
        timestamp = timestamp.strip()

        # æ­£ç¢ºçš„æ ¼å¼æ‡‰è©²æ˜¯ HH:MM:SS,mmm
        # å˜—è©¦åŒ¹é…ä¸¦ä¿®æ­£å„ç¨®éŒ¯èª¤æ ¼å¼

        # æƒ…æ³1: 0007:43,000 -> 00:07:43,000
        match = re.match(r'^(\d{2})(\d{2}):(\d{2}),(\d{3})$', timestamp)
        if match:
            return f"{match.group(1)}:{match.group(2)}:{match.group(3)},{match.group(4)}"

        # æƒ…æ³2: å·²ç¶“æ˜¯æ­£ç¢ºæ ¼å¼ 00:07:43,000
        if re.match(r'^\d{2}:\d{2}:\d{2},\d{3}$', timestamp):
            return timestamp

        # æƒ…æ³3: ç¼ºå°‘å‰å°é›¶ï¼Œä¾‹å¦‚ 7:43,000 -> 00:07:43,000
        match = re.match(r'^(\d{1,2}):(\d{2}),(\d{3})$', timestamp)
        if match:
            return f"00:{match.group(1).zfill(2)}:{match.group(2)},{match.group(3)}"

        # å¦‚æœç„¡æ³•åŒ¹é…ï¼Œè¿”å›åŸå§‹å€¼
        return timestamp

    def _validate_and_fix_srt(self, srt_content: str) -> str:
        """
        é©—è­‰ä¸¦ä¿®æ­£ SRT æ ¼å¼

        Args:
            srt_content: SRT å­—å¹•å…§å®¹

        Returns:
            ä¿®æ­£å¾Œçš„ SRT å…§å®¹
        """
        lines = srt_content.split('\n')
        fixed_lines = []

        for line in lines:
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ™‚é–“è»¸è¡Œï¼ˆåŒ…å« -->ï¼‰
            if '-->' in line:
                parts = line.split('-->')
                if len(parts) == 2:
                    start_time = self._fix_srt_timestamp(parts[0])
                    end_time = self._fix_srt_timestamp(parts[1])
                    fixed_lines.append(f"{start_time} --> {end_time}")
                else:
                    fixed_lines.append(line)
            else:
                fixed_lines.append(line)

        return '\n'.join(fixed_lines)

    def _get_rate_limit_for_model(self, model_name: str) -> tuple:
        """
        æ ¹æ“šæ¨¡å‹åç¨±è¿”å› rate limit è¨­å®š

        Returns:
            (rpm, tpm): requests per minute, tokens per minute
        """
        rate_limits = {
            "gemini-2.5-flash": (10, 250000),
            "gemini-2.5-pro": (5, 125000),
            "gemini-2.5-flash-lite": (15, 250000),
            "gemini-2.0-flash": (10, 250000),
        }
        return rate_limits.get(model_name, (10, 250000))  # é è¨­ä½¿ç”¨ flash çš„é™åˆ¶

    def _process_single_chunk(
        self,
        chunk: str,
        chunk_index: int,
        total_chunks: int,
        base_prompt_template: str,
        target_language: Optional[str] = None,
        retry_count: int = 0,
        max_retries: int = 2
    ) -> tuple:
        """
        è™•ç†å–®å€‹å­—å¹•ç‰‡æ®µï¼ˆæ”¯æ´è‡ªå‹•é‡è©¦ï¼‰

        Returns:
            (chunk_index, processed_chunk): ç´¢å¼•å’Œè™•ç†å¾Œçš„å…§å®¹
        """
        if total_chunks > 1:
            retry_suffix = f" (é‡è©¦ {retry_count}/{max_retries})" if retry_count > 0 else ""
            print(f"  ğŸ“„ è™•ç†ç¬¬ {chunk_index}/{total_chunks} æ®µ{retry_suffix}...")

        chunk_prompt = base_prompt_template + f"å­—å¹•å…§å®¹ï¼š\n\n{chunk}"

        # é¡¯ç¤ºç™¼é€çš„è³‡æ–™é‡
        chunk_chars = len(chunk)
        prompt_chars = len(chunk_prompt)
        print(f"     ğŸ“Š å­—å¹•ç‰‡æ®µå¤§å°: {chunk_chars:,} å­—å…ƒ")
        print(f"     ğŸ“Š å®Œæ•´æç¤ºè©å¤§å°: {prompt_chars:,} å­—å…ƒ")

        try:
            print(f"  â³ æ­£åœ¨å‘¼å« Gemini API...")

            # ä½¿ç”¨æ–°ç‰ˆ SDKï¼Œä¸¦å¢åŠ æœ€å¤§è¼¸å‡º token æ•¸
            response = self.client.models.generate_content(
                model=self.gemini_model,
                contents=chunk_prompt,
                config=types.GenerateContentConfig(
                    max_output_tokens=65536,
                    temperature=0.3,
                )
            )

            # æª¢æŸ¥ finish_reason å’Œé¡¯ç¤º token ä½¿ç”¨æƒ…æ³
            print(f"  ğŸ” æª¢æŸ¥ API å›æ‡‰...")
            if hasattr(response, 'candidates') and response.candidates:
                finish_reason = response.candidates[0].finish_reason if hasattr(response.candidates[0], 'finish_reason') else None
                print(f"     - finish_reason: {finish_reason}")

                if finish_reason and 'MAX_TOKENS' in str(finish_reason):
                    # é¡¯ç¤ºè©³ç´°çš„ token ä½¿ç”¨æƒ…æ³
                    if hasattr(response, 'usage_metadata'):
                        usage = response.usage_metadata
                        print(f"     âš ï¸  è¶…é token é™åˆ¶è©³æƒ…:")
                        if hasattr(usage, 'thoughts_token_count'):
                            print(f"        - æ€è€ƒ tokens: {usage.thoughts_token_count:,}")
                        if hasattr(usage, 'candidates_token_count'):
                            print(f"        - è¼¸å‡º tokens: {usage.candidates_token_count:,}")
                        if hasattr(usage, 'total_token_count'):
                            print(f"        - ç¸½è¨ˆ: {usage.total_token_count:,} / 65,536")

                    # å¦‚æœé‚„æœ‰é‡è©¦æ¬¡æ•¸ï¼Œå°‡æ­¤ç‰‡æ®µåˆ‡æˆå…©åŠé‡è©¦
                    if retry_count < max_retries:
                        print(f"     ğŸ”„ å°‡æ­¤ç‰‡æ®µåˆ‡æˆå…©åŠå¾Œé‡è©¦...")
                        # å°‡æ­¤ chunk åˆ‡æˆå…©åŠ
                        entries = re.split(r'\n\n+', chunk.strip())
                        mid = len(entries) // 2

                        if mid > 0:
                            chunk1 = '\n\n'.join(entries[:mid])
                            chunk2 = '\n\n'.join(entries[mid:])

                            print(f"     âœ‚ï¸  åˆ†å‰²ç‚ºå…©å€‹å­ç‰‡æ®µ: {len(chunk1):,} å’Œ {len(chunk2):,} å­—å…ƒ")

                            # éè¿´è™•ç†å…©å€‹å­ç‰‡æ®µ
                            _, processed1 = self._process_single_chunk(
                                chunk1, chunk_index, total_chunks, base_prompt_template,
                                target_language, retry_count + 1, max_retries
                            )
                            _, processed2 = self._process_single_chunk(
                                chunk2, chunk_index, total_chunks, base_prompt_template,
                                target_language, retry_count + 1, max_retries
                            )

                            # åˆä½µå…©å€‹çµæœ
                            combined = processed1 + '\n\n' + processed2
                            return (chunk_index, combined)

                    # ç„¡æ³•é‡è©¦ï¼Œæ‹‹å‡ºéŒ¯èª¤
                    error_msg = f"âŒ è¼¸å‡ºè¶…é token é™åˆ¶ï¼\n"
                    error_msg += f"     - æ­¤ç‰‡æ®µå­—å…ƒæ•¸: {chunk_chars:,}\n"
                    error_msg += f"     - å»ºè­°ï¼šæ¸›å°‘ max_chars åƒæ•¸ï¼ˆç›®å‰å¯èƒ½éœ€è¦è¨­ç‚º {chunk_chars // 2:,} ä»¥ä¸‹ï¼‰\n"
                    if hasattr(response, 'usage_metadata'):
                        error_msg += f"     - Token ä½¿ç”¨æƒ…æ³: {response.usage_metadata}\n"
                    raise ValueError(error_msg)

            # é¡¯ç¤º token ä½¿ç”¨çµ±è¨ˆ
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                print(f"     ğŸ“ˆ Token ä½¿ç”¨çµ±è¨ˆ:")
                if hasattr(usage, 'prompt_token_count'):
                    print(f"        - è¼¸å…¥ tokens: {usage.prompt_token_count:,}")
                if hasattr(usage, 'candidates_token_count'):
                    print(f"        - è¼¸å‡º tokens: {usage.candidates_token_count:,}")
                if hasattr(usage, 'thoughts_token_count') and usage.thoughts_token_count:
                    print(f"        - æ€è€ƒ tokens: {usage.thoughts_token_count:,}")
                if hasattr(usage, 'total_token_count'):
                    print(f"        - ç¸½è¨ˆ tokens: {usage.total_token_count:,}")

                # è¨ˆç®—å­—å…ƒèˆ‡ token çš„æ¯”ç‡
                if hasattr(usage, 'prompt_token_count') and prompt_chars > 0:
                    char_per_token = prompt_chars / usage.prompt_token_count
                    print(f"        - å­—å…ƒ/Token æ¯”ç‡: {char_per_token:.2f}")

            # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰æ•ˆ
            if not response.text:
                error_msg = f"API å›æ‡‰ç‚ºç©º\n"
                if hasattr(response, '__dict__'):
                    error_msg += f"     response å±¬æ€§: {response.__dict__}"
                raise ValueError(error_msg)

            print(f"  âœ… æˆåŠŸæ¥æ”¶åˆ°å›æ‡‰ (é•·åº¦: {len(response.text):,} å­—å…ƒ)")

            # æ¸…ç†å›æ‡‰
            cleaned_chunk = self._clean_llm_response(response.text)

            # é©—è­‰ä¸¦ä¿®æ­£ SRT æ ¼å¼
            cleaned_chunk = self._validate_and_fix_srt(cleaned_chunk)

            if total_chunks > 1:
                print(f"  âœ”ï¸  ç¬¬ {chunk_index}/{total_chunks} æ®µè™•ç†å®Œæˆ")

            return (chunk_index, cleaned_chunk)

        except Exception as e:
            print(f"  âŒ ç¬¬ {chunk_index}/{total_chunks} æ®µè™•ç†å¤±æ•—")
            print(f"     éŒ¯èª¤é¡å‹: {type(e).__name__}")
            print(f"     éŒ¯èª¤è¨Šæ¯: {str(e)}")
            print(f"\n  ğŸ›‘ ç”±æ–¼è™•ç†å¤±æ•—ï¼Œä¸­æ–·æ•´å€‹{'ç¿»è­¯' if target_language else 'æ ¡æ­£'}æµç¨‹")
            raise Exception(f"ç¬¬ {chunk_index}/{total_chunks} æ®µè™•ç†å¤±æ•—: {str(e)}")

    def correct_subtitle_with_llm(
        self,
        subtitle_content: str,
        custom_prompt: Optional[str] = None,
        context: Optional[str] = None,
        target_language: Optional[str] = None,
        max_chars: int = 15000
    ) -> str:
        """
        ä½¿ç”¨ Gemini LLM æ ¡æ­£å­—å¹•ï¼ˆä¸¦å¯é¸æ“‡ç¿»è­¯ï¼‰

        Args:
            subtitle_content: åŸå§‹å­—å¹•å…§å®¹
            custom_prompt: è‡ªå®šç¾©æç¤ºè©
            context: é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Š
            target_language: ç›®æ¨™ç¿»è­¯èªè¨€ï¼ˆå¦‚æœéœ€è¦ç¿»è­¯ï¼‰
            max_chars: æ¯å€‹ç‰‡æ®µçš„æœ€å¤§å­—å…ƒæ•¸ï¼ˆé è¨­ 15000ï¼Œå¹³è¡¡è™•ç†é€Ÿåº¦èˆ‡ token é™åˆ¶ï¼‰

        Returns:
            æ ¡æ­£å¾Œï¼ˆæˆ–ç¿»è­¯å¾Œï¼‰çš„å­—å¹•å…§å®¹
        """
        if target_language:
            print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨ Gemini AI ({self.gemini_model}) æ ¡æ­£ä¸¦ç¿»è­¯å­—å¹•ç‚º {target_language}...")
        else:
            print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨ Gemini AI ({self.gemini_model}) æ ¡æ­£å­—å¹•...")

        # æª¢æŸ¥æ˜¯å¦æœ‰ client
        if not self.client:
            raise ValueError("éœ€è¦ Gemini API key æ‰èƒ½ä½¿ç”¨ AI æ ¡æ­£/ç¿»è­¯åŠŸèƒ½")

        # åˆ†å‰²å­—å¹•ç‚ºå¤šå€‹ç‰‡æ®µï¼ˆåŸºæ–¼å­—å…ƒæ•¸ï¼‰
        chunks = self._split_subtitle_into_chunks(subtitle_content, max_chars=max_chars)
        total_chunks = len(chunks)

        if total_chunks > 1:
            print(f"ğŸ“ å­—å¹•è¼ƒé•·ï¼Œå°‡åˆ†æˆ {total_chunks} æ®µè™•ç†ï¼ˆæ¯æ®µæœ€å¤š {max_chars:,} å­—å…ƒï¼‰...")
            # é¡¯ç¤ºæ¯å€‹ chunk çš„å¯¦éš›å¤§å°
            for i, chunk in enumerate(chunks, 1):
                print(f"   - ç¬¬ {i} æ®µ: {len(chunk):,} å­—å…ƒ")

        processed_chunks = []

        # èªè¨€å°ç…§è¡¨
        language_names = {
            "zh": "ç¹é«”ä¸­æ–‡",
            "zh-TW": "ç¹é«”ä¸­æ–‡",
            "zh-CN": "ç°¡é«”ä¸­æ–‡",
            "en": "è‹±æ–‡",
            "ja": "æ—¥æ–‡",
            "ko": "éŸ“æ–‡",
            "es": "è¥¿ç­ç‰™æ–‡",
            "fr": "æ³•æ–‡",
            "de": "å¾·æ–‡",
            "it": "ç¾©å¤§åˆ©æ–‡",
            "pt": "è‘¡è„ç‰™æ–‡",
            "ru": "ä¿„æ–‡",
            "ar": "é˜¿æ‹‰ä¼¯æ–‡",
            "th": "æ³°æ–‡",
            "vi": "è¶Šå—æ–‡"
        }

        # æº–å‚™åŸºç¤æç¤ºè©
        if target_language:
            # ç¿»è­¯æ¨¡å¼
            target_lang_name = language_names.get(target_language, target_language)

            # åˆ¤æ–·ç›®æ¨™èªè¨€æ˜¯å¦ç‚ºä¸­æ–‡
            is_chinese_target = target_language in ["zh", "zh-TW", "zh-CN"]

            base_prompt_template = f"""è«‹å°‡ä»¥ä¸‹ SRT æ ¼å¼çš„å­—å¹•æª”æ¡ˆç¿»è­¯æˆ{target_lang_name}ã€‚

é‡è¦è¦å‰‡ï¼š
1. å¿…é ˆä¿æŒå®Œæ•´çš„ SRT æ ¼å¼ï¼ˆåºè™Ÿã€æ™‚é–“è»¸ã€å­—å¹•æ–‡å­—ï¼‰
2. ä¸è¦æ”¹è®Šå­—å¹•çš„æ™‚é–“è»¸
3. ç¿»è­¯è¦è‡ªç„¶æµæš¢ï¼Œç¬¦åˆç›®æ¨™èªè¨€çš„è¡¨é”ç¿’æ…£
4. å°ˆæœ‰åè©ä¿æŒåŸæ–‡æˆ–ä½¿ç”¨é€šç”¨è­¯å
5. æ ¹æ“šä¸Šä¸‹æ–‡æº–ç¢ºç¿»è­¯
6. å¿…é ˆè™•ç†å®Œæ‰€æœ‰å­—å¹•æ¢ç›®ï¼Œä¸è¦æˆªæ–·
7. ç›´æ¥è¼¸å‡º SRT æ ¼å¼å…§å®¹ï¼Œä¸è¦åŠ ä»»ä½•èªªæ˜æ–‡å­—æˆ–å‰è¨€
"""

            # å¦‚æœç›®æ¨™èªè¨€æ˜¯ä¸­æ–‡ï¼ŒåŠ å…¥æ¨™é»ç¬¦è™Ÿè¦ç¯„
            if is_chinese_target:
                base_prompt_template += """8. ã€é‡è¦ã€‘ä¸­æ–‡å­—å¹•æ¨™é»ç¬¦è™Ÿè¦ç¯„ï¼š
   - å¥å°¾é€šå¸¸ä¸åŠ æ¨™é»ç¬¦è™Ÿï¼ˆå¥è™Ÿã€é€—è™Ÿç­‰ï¼‰
   - åªæœ‰åœ¨ç–‘å•å¥æ™‚æ‰åŠ å•è™Ÿï¼ˆï¼Ÿï¼‰
   - åªæœ‰åœ¨æ„Ÿå˜†å¥æ™‚æ‰åŠ é©šå˜†è™Ÿï¼ˆï¼ï¼‰
   - å¥ä¸­å¯ä»¥ä½¿ç”¨é€—è™Ÿï¼ˆï¼Œï¼‰ä¾†åˆ†éš”èªæ„
   - ä¾‹å¦‚ï¼šã€Œä½ å¥½å—ã€è€Œä¸æ˜¯ã€Œä½ å¥½å—ã€‚ã€
   - ä¾‹å¦‚ï¼šã€Œé€™æ˜¯ä»€éº¼ï¼Ÿã€ï¼ˆç–‘å•å¥ä¿ç•™å•è™Ÿï¼‰
   - ä¾‹å¦‚ï¼šã€Œå¤ªæ£’äº†ï¼ã€ï¼ˆæ„Ÿå˜†å¥ä¿ç•™é©šå˜†è™Ÿï¼‰

"""
            else:
                base_prompt_template += "\n"

        else:
            # æ ¡æ­£æ¨¡å¼
            base_prompt_template = """è«‹æ ¡æ­£ä»¥ä¸‹ SRT æ ¼å¼çš„å­—å¹•æª”æ¡ˆã€‚

é‡è¦è¦å‰‡ï¼š
1. å¿…é ˆä¿æŒå®Œæ•´çš„ SRT æ ¼å¼ï¼ˆåºè™Ÿã€æ™‚é–“è»¸ã€å­—å¹•æ–‡å­—ï¼‰
2. ä¸è¦æ”¹è®Šå­—å¹•çš„æ™‚é–“è»¸
3. ä¿®æ­£éŒ¯åˆ¥å­—ã€æ¨™é»ç¬¦è™ŸéŒ¯èª¤
4. æ ¹æ“šä¸Šä¸‹æ–‡èª¿æ•´æ–·å¥
5. ä¿®æ­£èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼ˆå¦‚åŒéŸ³å­—ï¼‰
6. ä¿æŒåŸæ„ï¼Œä¸è¦éåº¦æ½¤é£¾
7. å¿…é ˆè™•ç†å®Œæ‰€æœ‰å­—å¹•æ¢ç›®ï¼Œä¸è¦æˆªæ–·
8. ç›´æ¥è¼¸å‡º SRT æ ¼å¼å…§å®¹ï¼Œä¸è¦åŠ ä»»ä½•èªªæ˜æ–‡å­—æˆ–å‰è¨€
9. ã€é‡è¦ã€‘ä¸­æ–‡å­—å¹•æ¨™é»ç¬¦è™Ÿè¦ç¯„ï¼š
   - å¥å°¾é€šå¸¸ä¸åŠ æ¨™é»ç¬¦è™Ÿï¼ˆå¥è™Ÿã€é€—è™Ÿç­‰ï¼‰
   - åªæœ‰åœ¨ç–‘å•å¥æ™‚æ‰åŠ å•è™Ÿï¼ˆï¼Ÿï¼‰
   - åªæœ‰åœ¨æ„Ÿå˜†å¥æ™‚æ‰åŠ é©šå˜†è™Ÿï¼ˆï¼ï¼‰
   - å¥ä¸­å¯ä»¥ä½¿ç”¨é€—è™Ÿï¼ˆï¼Œï¼‰ä¾†åˆ†éš”èªæ„
   - ä¾‹å¦‚ï¼šã€Œä½ å¥½å—ã€è€Œä¸æ˜¯ã€Œä½ å¥½å—ã€‚ã€
   - ä¾‹å¦‚ï¼šã€Œé€™æ˜¯ä»€éº¼ï¼Ÿã€ï¼ˆç–‘å•å¥ä¿ç•™å•è™Ÿï¼‰
   - ä¾‹å¦‚ï¼šã€Œå¤ªæ£’äº†ï¼ã€ï¼ˆæ„Ÿå˜†å¥ä¿ç•™é©šå˜†è™Ÿï¼‰

"""

        if context:
            base_prompt_template += f"é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼š{context}\n\n"

        if custom_prompt:
            base_prompt_template += f"{custom_prompt}\n\n"

        # å–å¾— rate limit
        rpm, tpm = self._get_rate_limit_for_model(self.gemini_model)

        # è¨ˆç®—æ¯å€‹è«‹æ±‚ä¹‹é–“éœ€è¦ç­‰å¾…çš„æ™‚é–“ï¼ˆç§’ï¼‰
        delay_between_requests = 60.0 / rpm if total_chunks > 1 else 0

        if total_chunks > 1:
            print(f"âš¡ ä½¿ç”¨å¹³è¡Œè™•ç†åŠ é€Ÿï¼ˆè€ƒæ…® API rate limit: {rpm} RPMï¼‰")
            if delay_between_requests > 0:
                print(f"   æ¯å€‹è«‹æ±‚é–“éš”: {delay_between_requests:.1f} ç§’")

        # ä½¿ç”¨ ThreadPoolExecutor å¹³è¡Œè™•ç†ï¼Œä½†é™åˆ¶åŒæ™‚åŸ·è¡Œçš„æ•¸é‡
        max_workers = min(total_chunks, rpm)  # ä¸è¶…é RPM é™åˆ¶
        processed_chunks_dict = {}

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™ï¼Œä¸¦åŠ å…¥å»¶é²é¿å…è¶…é rate limit
            futures = {}
            for i, chunk in enumerate(chunks, 1):
                # å»¶é²æäº¤ä»¥ç¬¦åˆ rate limit
                if i > 1 and delay_between_requests > 0:
                    time.sleep(delay_between_requests)

                future = executor.submit(
                    self._process_single_chunk,
                    chunk,
                    i,
                    total_chunks,
                    base_prompt_template,
                    target_language
                )
                futures[future] = i

            # æ”¶é›†çµæœ
            for future in as_completed(futures):
                chunk_index, processed_chunk = future.result()
                processed_chunks_dict[chunk_index] = processed_chunk

        # æŒ‰ç…§åŸå§‹é †åºæ’åˆ—è™•ç†å¾Œçš„ç‰‡æ®µ
        processed_chunks = [processed_chunks_dict[i] for i in sorted(processed_chunks_dict.keys())]

        # åˆä½µæ‰€æœ‰è™•ç†éçš„ç‰‡æ®µ
        if total_chunks > 1:
            print(f"ğŸ”— æ­£åœ¨åˆä½µ {total_chunks} å€‹ç‰‡æ®µä¸¦é‡æ–°ç·¨è™Ÿ...")
            final_subtitle = self._merge_subtitle_chunks(processed_chunks)
        else:
            final_subtitle = processed_chunks[0] if processed_chunks else subtitle_content

        print(f"âœ… å­—å¹•{'ç¿»è­¯' if target_language else 'æ ¡æ­£'}å®Œæˆ")
        return final_subtitle
    
    def _clean_llm_response(self, text: str) -> str:
        """
        æ¸…ç† LLM å›æ‡‰ï¼Œç§»é™¤å¯èƒ½çš„èªªæ˜æ–‡å­—å’Œæ ¼å¼æ¨™è¨˜

        Args:
            text: LLM çš„åŸå§‹å›æ‡‰

        Returns:
            æ¸…ç†å¾Œçš„ SRT å…§å®¹
        """
        import re

        # ç¢ºä¿ text ä¸æ˜¯ None
        if not text:
            return ""

        # ç§»é™¤é–‹é ­å¯èƒ½çš„èªªæ˜æ–‡å­—ï¼ˆä¾‹å¦‚ï¼š"ä»¥ä¸‹æ˜¯ç¿»è­¯å¾Œçš„å…§å®¹ï¼š"ï¼‰
        lines = text.strip().split('\n')
        
        # æ‰¾åˆ°ç¬¬ä¸€å€‹ SRT åºè™Ÿï¼ˆç´”æ•¸å­—ï¼‰çš„ä½ç½®
        start_idx = 0
        for i, line in enumerate(lines):
            if line.strip().isdigit():
                start_idx = i
                break
        
        # å¾ç¬¬ä¸€å€‹åºè™Ÿé–‹å§‹å–å…§å®¹
        cleaned_lines = lines[start_idx:]
        
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
        result = '\n'.join(cleaned_lines)
        result = re.sub(r'^```srt\n', '', result)
        result = re.sub(r'^```\n', '', result)
        result = re.sub(r'\n```$', '', result)

        return result.strip()

    def save_corrected_subtitle(self, content: str, original_path: str, target_language: Optional[str] = None) -> str:
        """
        å„²å­˜æ ¡æ­£å¾Œçš„å­—å¹•
        
        Args:
            content: æ ¡æ­£å¾Œçš„å­—å¹•å…§å®¹
            original_path: åŸå§‹å­—å¹•è·¯å¾‘
            target_language: å¦‚æœæœ‰ç¿»è­¯ï¼Œæ¨™è¨»ç›®æ¨™èªè¨€
            
        Returns:
            æ ¡æ­£å¾Œå­—å¹•çš„æª”æ¡ˆè·¯å¾‘
        """
        if target_language:
            corrected_path = original_path.replace('.srt', f'_{target_language}.srt')
        else:
            corrected_path = original_path.replace('.srt', '_corrected.srt')
        
        with open(corrected_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"ğŸ’¾ {'ç¿»è­¯' if target_language else 'æ ¡æ­£'}å¾Œçš„å­—å¹•å·²å„²å­˜: {corrected_path}")
        return corrected_path
    
    def embed_subtitle_to_video(
        self, 
        video_path: str, 
        subtitle_path: str, 
        output_dir: str = "./output"
    ) -> str:
        """
        ä½¿ç”¨ FFmpeg å°‡å­—å¹•åµŒå…¥å½±ç‰‡
        
        Args:
            video_path: å½±ç‰‡æª”æ¡ˆè·¯å¾‘
            subtitle_path: å­—å¹•æª”æ¡ˆè·¯å¾‘
            output_dir: è¼¸å‡ºç›®éŒ„
            
        Returns:
            å¸¶å­—å¹•çš„å½±ç‰‡æª”æ¡ˆè·¯å¾‘
        """
        print("ğŸ¬ æ­£åœ¨å°‡å­—å¹•åµŒå…¥å½±ç‰‡...")
        
        os.makedirs(output_dir, exist_ok=True)
        video_name = Path(video_path).stem
        output_path = os.path.join(output_dir, f"{video_name}_with_subtitles.mp4")
        
        # å°‡è·¯å¾‘è½‰æ›ç‚ºçµ•å°è·¯å¾‘
        subtitle_path_abs = os.path.abspath(subtitle_path)
        video_path_abs = os.path.abspath(video_path)
        
        import shutil
        import tempfile
        
        # å‰µå»ºä¸€å€‹è‡¨æ™‚å·¥ä½œç›®éŒ„
        temp_dir = tempfile.mkdtemp()
        
        try:
            # æ–¹æ³•ï¼šä½¿ç”¨ ASS æ ¼å¼ï¼ˆæ›´å¯é ï¼‰+ è¤‡è£½åˆ°ç°¡å–®è·¯å¾‘
            temp_video = os.path.join(temp_dir, "input.mp4")
            temp_subtitle_srt = os.path.join(temp_dir, "subtitle.srt")
            temp_subtitle_ass = os.path.join(temp_dir, "subtitle.ass")
            
            # è¤‡è£½å½±ç‰‡å’Œå­—å¹•åˆ°è‡¨æ™‚ç›®éŒ„
            print("ğŸ“‹ è¤‡è£½æª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„...")
            shutil.copy2(video_path_abs, temp_video)
            shutil.copy2(subtitle_path_abs, temp_subtitle_srt)
            
            # å…ˆå°‡ SRT è½‰æ›ç‚º ASS æ ¼å¼ï¼ˆæ›´å¯é ï¼‰
            print("ğŸ”„ è½‰æ›å­—å¹•æ ¼å¼...")
            convert_cmd = [
                FFMPEG_CMD,
                "-i", temp_subtitle_srt,
                "-y",
                temp_subtitle_ass
            ]
            
            try:
                subprocess.run(convert_cmd, check=True, capture_output=True, text=True)
            except subprocess.CalledProcessError as e:
                print(f"âš ï¸  å­—å¹•è½‰æ›å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹ SRT: {e.stderr}")
                # å¦‚æœè½‰æ›å¤±æ•—ï¼Œç›´æ¥ä½¿ç”¨ SRT
                temp_subtitle_ass = temp_subtitle_srt
            
            # ä½¿ç”¨ ass filterï¼ˆæ¯” subtitles filter æ›´ç©©å®šï¼‰
            print("ğŸ¨ åµŒå…¥å­—å¹•åˆ°å½±ç‰‡...")
            
            if temp_subtitle_ass.endswith('.ass'):
                # ä½¿ç”¨ ass filter
                cmd = [
                    FFMPEG_CMD,
                    "-i", temp_video,
                    "-vf", f"ass={temp_subtitle_ass}",
                    "-c:a", "copy",
                    "-y",
                    output_path
                ]
            else:
                # ä½¿ç”¨ subtitles filter
                cmd = [
                    FFMPEG_CMD,
                    "-i", temp_video,
                    "-vf", f"subtitles={temp_subtitle_srt}",
                    "-c:a", "copy",
                    "-y",
                    output_path
                ]
            
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            print(f"âœ… å½±ç‰‡è™•ç†å®Œæˆ: {output_path}")
            return output_path
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ å½±ç‰‡è™•ç†å¤±æ•—")
            print(f"éŒ¯èª¤è¨Šæ¯: {e.stderr}")
            
            # å¦‚æœä¸Šé¢çš„æ–¹æ³•éƒ½å¤±æ•—ï¼Œå˜—è©¦æœ€å¾Œä¸€æ‹›ï¼šä½¿ç”¨è»Ÿå­—å¹•ï¼ˆä¸ç‡’éŒ„ï¼‰
            print("âš ï¸  å˜—è©¦ä½¿ç”¨è»Ÿå­—å¹•æ–¹å¼ï¼ˆå­—å¹•ä¸æœƒç‡’éŒ„åˆ°å½±ç‰‡ä¸­ï¼Œä½†æœƒä½œç‚ºç¨ç«‹è»Œé“ï¼‰...")
            
            try:
                soft_sub_cmd = [
                    FFMPEG_CMD,
                    "-i", video_path_abs,
                    "-i", subtitle_path_abs,
                    "-c", "copy",
                    "-c:s", "mov_text",
                    "-metadata:s:s:0", "language=chi",
                    "-y",
                    output_path
                ]
                
                subprocess.run(soft_sub_cmd, check=True, capture_output=True, text=True)
                print(f"âœ… å½±ç‰‡è™•ç†å®Œæˆï¼ˆä½¿ç”¨è»Ÿå­—å¹•ï¼‰: {output_path}")
                print("â„¹ï¸  æ³¨æ„ï¼šå­—å¹•ä»¥ç¨ç«‹è»Œé“å½¢å¼å­˜åœ¨ï¼Œéœ€è¦æ’­æ”¾å™¨æ”¯æ´æ‰èƒ½é¡¯ç¤º")
                return output_path
                
            except subprocess.CalledProcessError as e2:
                print(f"âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—")
                print(f"è»Ÿå­—å¹•éŒ¯èª¤: {e2.stderr}")
                raise
                
        finally:
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            try:
                shutil.rmtree(temp_dir)
            except:
                pass
    
    def process(
        self,
        input_source: str,
        is_youtube: bool = False,
        custom_prompt: Optional[str] = None,
        context: Optional[str] = None,
        skip_correction: bool = False,
        target_language: Optional[str] = None,
        existing_subtitle: Optional[str] = None,
        skip_download: bool = False,
        skip_transcribe: bool = False,
        only_embed: bool = False
    ) -> str:
        """
        å®Œæ•´è™•ç†æµç¨‹
        
        Args:
            input_source: YouTube URL æˆ–æœ¬åœ°å½±ç‰‡è·¯å¾‘
            is_youtube: æ˜¯å¦ç‚º YouTube é€£çµ
            custom_prompt: è‡ªå®šç¾© AI æ ¡æ­£æç¤ºè©
            context: é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Š
            skip_correction: æ˜¯å¦è·³é AI æ ¡æ­£
            target_language: ç›®æ¨™ç¿»è­¯èªè¨€ï¼ˆå¦‚æœéœ€è¦ç¿»è­¯ï¼‰
            existing_subtitle: ç¾æœ‰å­—å¹•æª”æ¡ˆè·¯å¾‘ï¼ˆå¦‚æœæä¾›å‰‡è·³éè½‰éŒ„ï¼‰
            skip_download: è·³éä¸‹è¼‰æ­¥é©Ÿï¼ˆåƒ…ç•¶æä¾›æœ¬åœ°å½±ç‰‡è·¯å¾‘æ™‚ï¼‰
            skip_transcribe: è·³éè½‰éŒ„æ­¥é©Ÿï¼ˆéœ€è¦æä¾› existing_subtitleï¼‰
            only_embed: åªåŸ·è¡Œå­—å¹•åµŒå…¥ï¼ˆéœ€è¦æä¾›å½±ç‰‡å’Œå­—å¹•ï¼Œè·³éæ‰€æœ‰å…¶ä»–æ­¥é©Ÿï¼‰
            
        Returns:
            æœ€çµ‚å¸¶å­—å¹•çš„å½±ç‰‡è·¯å¾‘
        """
        print("=" * 60)
        print("ğŸš€ é–‹å§‹è™•ç†å½±ç‰‡å­—å¹•")
        print("=" * 60)
        
        # æ­¥é©Ÿ 1: å–å¾—å½±ç‰‡
        if skip_download and not is_youtube:
            video_path = input_source
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ: {video_path}")
            print(f"â­ï¸  è·³éä¸‹è¼‰ï¼Œä½¿ç”¨ç¾æœ‰å½±ç‰‡: {video_path}")
        elif is_youtube:
            video_path = self.download_youtube_video(input_source)
        else:
            video_path = input_source
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ: {video_path}")
        
        # å¦‚æœæ˜¯ç´”åµŒå…¥æ¨¡å¼
        if only_embed:
            if not existing_subtitle:
                raise ValueError("ç´”åµŒå…¥æ¨¡å¼éœ€è¦æä¾› --subtitle åƒæ•¸")
            subtitle_path = existing_subtitle
            if not os.path.exists(subtitle_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å­—å¹•æª”æ¡ˆ: {subtitle_path}")
            print(f"â­ï¸  åƒ…åŸ·è¡Œå­—å¹•åµŒå…¥ï¼Œä½¿ç”¨å­—å¹•: {subtitle_path}")
            output_video_path = self.embed_subtitle_to_video(video_path, subtitle_path)
            print("=" * 60)
            print("ğŸ‰ å­—å¹•åµŒå…¥å®Œæˆï¼")
            print(f"ğŸ“¹ æœ€çµ‚å½±ç‰‡: {output_video_path}")
            print("=" * 60)
            return output_video_path
        
        # æ­¥é©Ÿ 2: è½‰éŒ„å­—å¹•
        if existing_subtitle:
            subtitle_path = existing_subtitle
            if not os.path.exists(subtitle_path):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å­—å¹•æª”æ¡ˆ: {subtitle_path}")
            print(f"â­ï¸  è·³éè½‰éŒ„ï¼Œä½¿ç”¨ç¾æœ‰å­—å¹•: {subtitle_path}")
        elif skip_transcribe:
            raise ValueError("å¦‚æœè¦è·³éè½‰éŒ„ï¼Œå¿…é ˆæä¾› existing_subtitle åƒæ•¸")
        else:
            subtitle_path = self.transcribe_video(video_path)
        
        # æ­¥é©Ÿ 3: AI æ ¡æ­£/ç¿»è­¯å­—å¹•ï¼ˆå¯é¸ï¼‰
        if not skip_correction:
            subtitle_content = self.read_subtitle_file(subtitle_path)
            corrected_content = self.correct_subtitle_with_llm(
                subtitle_content, 
                custom_prompt=custom_prompt,
                context=context,
                target_language=target_language
            )
            subtitle_path = self.save_corrected_subtitle(
                corrected_content, 
                subtitle_path,
                target_language=target_language
            )
        else:
            print("â­ï¸  è·³é AI å­—å¹•æ ¡æ­£")
        
        # æ­¥é©Ÿ 4: åµŒå…¥å­—å¹•åˆ°å½±ç‰‡
        output_video_path = self.embed_subtitle_to_video(video_path, subtitle_path)
        
        print("=" * 60)
        print("ğŸ‰ æ‰€æœ‰è™•ç†å®Œæˆï¼")
        print(f"ğŸ“¹ æœ€çµ‚å½±ç‰‡: {output_video_path}")
        print("=" * 60)
        
        return output_video_path


def main():
    parser = argparse.ArgumentParser(
        description="è‡ªå‹•åŒ–å½±ç‰‡å­—å¹•è™•ç†å·¥å…· - æ”¯æ´ YouTube ä¸‹è¼‰ã€Whisper è½‰éŒ„ã€Gemini AI æ ¡æ­£/ç¿»è­¯ã€FFmpeg åµŒå…¥å­—å¹•",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # å®Œæ•´æµç¨‹ï¼šè™•ç† YouTube å½±ç‰‡
  python subtitle_tool.py --youtube "https://www.youtube.com/watch?v=xxxxx" --api-key "YOUR_GEMINI_API_KEY"
  
  # å®Œæ•´æµç¨‹ï¼šè™•ç†æœ¬åœ°è‹±æ–‡å½±ç‰‡ä¸¦ç¿»è­¯æˆç¹é«”ä¸­æ–‡
  python subtitle_tool.py --video "./video.mp4" --api-key "KEY" --source-lang en --translate zh-TW
  
  # è·³éä¸‹è¼‰å’Œè½‰éŒ„ï¼šåƒ…æ ¡æ­£/ç¿»è­¯ç¾æœ‰å­—å¹•ä¸¦åµŒå…¥å½±ç‰‡
  python subtitle_tool.py --video "./video.mp4" --subtitle "./video.srt" --api-key "KEY" --translate en
  
  # ç´”å­—å¹•åµŒå…¥ï¼šç›´æ¥å°‡å·²è™•ç†å¥½çš„å­—å¹•åµŒå…¥å½±ç‰‡ï¼ˆä¸ä½¿ç”¨ AIï¼‰
  python subtitle_tool.py --video "./video.mp4" --subtitle "./video_translated.srt" --only-embed
  
  # ä½¿ç”¨è‡ªå®šç¾© Gemini æ¨¡å‹
  python subtitle_tool.py --video "./video.mp4" --api-key "KEY" --gemini-model "gemini-2.5-pro"
  
æ”¯æ´çš„èªè¨€ä»£ç¢¼:
  zh/zh-TW (ç¹é«”ä¸­æ–‡), zh-CN (ç°¡é«”ä¸­æ–‡), en (è‹±æ–‡), ja (æ—¥æ–‡), ko (éŸ“æ–‡)
  es (è¥¿ç­ç‰™æ–‡), fr (æ³•æ–‡), de (å¾·æ–‡), it (ç¾©å¤§åˆ©æ–‡), pt (è‘¡è„ç‰™æ–‡)
  ru (ä¿„æ–‡), ar (é˜¿æ‹‰ä¼¯æ–‡), th (æ³°æ–‡), vi (è¶Šå—æ–‡), auto (è‡ªå‹•åµæ¸¬)
  
å¯ç”¨çš„ Gemini æ¨¡å‹:
  gemini-2.5-flash (æ¨è–¦ï¼Œæ€§åƒ¹æ¯”æœ€é«˜)
  gemini-2.5-flash-lite (æœ€å¿«ï¼Œæˆæœ¬æœ€ä½)
  gemini-2.5-pro (æœ€å¼·å¤§ï¼Œæ€è€ƒèƒ½åŠ›æœ€å¥½)
  gemini-2.0-flash (ç¬¬äºŒä»£ï¼Œé•·ä¸Šä¸‹æ–‡)
        """
    )
    
    # è¼¸å…¥ä¾†æº
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument("--youtube", "-y", help="YouTube å½±ç‰‡ç¶²å€")
    input_group.add_argument("--video", "-v", help="æœ¬åœ°å½±ç‰‡æª”æ¡ˆè·¯å¾‘")
    
    # API è¨­å®š
    parser.add_argument("--api-key", "-k", help="Gemini API é‡‘é‘°ï¼ˆä½¿ç”¨ --only-embed æ™‚ä¸éœ€è¦ï¼‰")
    
    # æ¨¡å‹è¨­å®š
    parser.add_argument(
        "--gemini-model", "-gm",
        default="gemini-2.5-flash",
        help="Gemini æ¨¡å‹åç¨± (é è¨­: gemini-2.5-flash)"
    )
    
    # èªè¨€è¨­å®š
    parser.add_argument(
        "--source-lang", "-sl",
        default="zh",
        help="å½±ç‰‡çš„åŸå§‹èªè¨€ (é è¨­: zh ä¸­æ–‡ï¼Œå¯ç”¨ auto è‡ªå‹•åµæ¸¬)"
    )
    
    parser.add_argument(
        "--translate", "-t",
        help="ç¿»è­¯æˆç›®æ¨™èªè¨€ (ä¾‹å¦‚: en, ja, ko, zh-TW ç­‰)"
    )
    
    # Whisper è¨­å®š
    parser.add_argument(
        "--whisper-model", "-w",
        default="base",
        choices=["tiny", "base", "small", "medium", "large"],
        help="Whisper æ¨¡å‹å¤§å° (é è¨­: base)"
    )
    
    # AI æ ¡æ­£è¨­å®š
    parser.add_argument("--prompt", "-p", help="è‡ªå®šç¾© AI æ ¡æ­£æç¤ºè©")
    parser.add_argument("--context", "-c", help="é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Š")
    parser.add_argument("--skip-correction", "-s", action="store_true", help="è·³é AI å­—å¹•æ ¡æ­£")
    
    # è·³éæ­¥é©Ÿçš„é¸é …
    parser.add_argument(
        "--subtitle", "-sub",
        help="ç¾æœ‰å­—å¹•æª”æ¡ˆè·¯å¾‘ï¼ˆæä¾›æ­¤é¸é …å°‡è·³éä¸‹è¼‰å’Œè½‰éŒ„æ­¥é©Ÿï¼‰"
    )
    
    parser.add_argument(
        "--only-embed", "-oe",
        action="store_true",
        help="åƒ…åŸ·è¡Œå­—å¹•åµŒå…¥ï¼ˆéœ€è¦åŒæ™‚æä¾› --video å’Œ --subtitleï¼Œè·³éæ‰€æœ‰å…¶ä»–æ­¥é©ŸåŒ…æ‹¬ AI æ ¡æ­£ï¼‰"
    )
    
    args = parser.parse_args()
    
    # æª¢æŸ¥ only-embed æ¨¡å¼çš„å¿…è¦åƒæ•¸
    if args.only_embed:
        if not args.video or not args.subtitle:
            parser.error("--only-embed mode requires both --video and --subtitle")
        if args.youtube:
            parser.error("--only-embed mode cannot be used with --youtube")
    
    # æª¢æŸ¥ API keyï¼ˆåƒ…åœ¨éœ€è¦ AI è™•ç†æ™‚ï¼‰
    if not args.only_embed and not args.skip_correction and not args.api_key:
        parser.error("--api-key is required unless using --only-embed or --skip-correction")
    
    # æª¢æŸ¥å¿…è¦å·¥å…·
    missing_tools = []

    # æª¢æŸ¥ä¸¦åˆå§‹åŒ– ffmpeg
    print("ğŸ” æª¢æŸ¥ FFmpeg...")
    ffmpeg_path = get_ffmpeg_path()

    try:
        result = subprocess.run([ffmpeg_path, "-version"], capture_output=True, check=True, timeout=5)
        print(f"âœ… FFmpeg å·²å°±ç·’: {ffmpeg_path}")
    except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired) as e:
        print(f"âŒ FFmpeg æª¢æŸ¥å¤±æ•—: {e}")
        missing_tools.append("ffmpeg")
    
    # æª¢æŸ¥ yt-dlpï¼ˆåƒ…åœ¨éœ€è¦ä¸‹è¼‰ YouTube å½±ç‰‡æ™‚ï¼‰
    if args.youtube and not args.only_embed:
        try:
            subprocess.run(["yt-dlp", "--version"], capture_output=True, check=True, timeout=5)
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            missing_tools.append("yt-dlp")
    
    # æª¢æŸ¥ whisperï¼ˆåƒ…åœ¨éœ€è¦è½‰éŒ„æ™‚ï¼‰
    if not args.subtitle and not args.only_embed:
        try:
            import whisper
        except ImportError:
            missing_tools.append("whisper")
    
    if missing_tools:
        print("âŒ ç¼ºå°‘å¿…è¦å·¥å…·ï¼Œè«‹å…ˆå®‰è£:")
        for tool in missing_tools:
            if tool == "yt-dlp":
                print(f"  pip install yt-dlp")
            elif tool == "whisper":
                print(f"  pip install openai-whisper")
            elif tool == "ffmpeg":
                print(f"  pip install static-ffmpeg")
                print(f"  # æˆ–è€…æ‰‹å‹•å®‰è£: brew install ffmpeg (macOS)")
        sys.exit(1)
    
    # åˆå§‹åŒ–è™•ç†å™¨
    processor = VideoSubtitleProcessor(
        gemini_api_key=args.api_key,  # åœ¨ only-embed æ¨¡å¼ä¸‹å¯ä»¥æ˜¯ None
        whisper_model=args.whisper_model,
        source_language=args.source_lang,
        gemini_model=args.gemini_model
    )
    
    # é–‹å§‹è™•ç†
    try:
        input_source = args.youtube if args.youtube else args.video
        is_youtube = args.youtube is not None
        
        processor.process(
            input_source=input_source,
            is_youtube=is_youtube,
            custom_prompt=args.prompt,
            context=args.context,
            skip_correction=args.skip_correction,
            target_language=args.translate,
            existing_subtitle=args.subtitle,
            skip_download=args.subtitle is not None and not is_youtube,
            skip_transcribe=args.subtitle is not None,
            only_embed=args.only_embed
        )
        
    except Exception as e:
        print(f"\nâŒ è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
